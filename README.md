# dlupi-heteroscedastic-dropout

This is modified version of project, simplified (reduced by code unused for my reasearch)  and ported to the python 3.10 from python 2.7. 

### Citation

```
@InProceedings{Lambert_2018_CVPR,
author = {Lambert, John and Sener, Ozan and Savarese, Silvio},
title = {Deep Learning Under Privileged Information Using Heteroscedastic Dropout},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}
```

In this repository we provide:

- ...

We also provide implementations of various baselines that use privileged information, including:

- N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov. [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf). In JMLR, 2014. Pages 1929âˆ’1958.
- A. Achille, S. Soatto. [Information Dropout: learning optimal representations through noisy computation](https://arxiv.org/abs/1611.01353). Transactions on Pattern Analysis and Machine Intelligence (PAMI), 2018.
- K. Simonyan, A. Zisserman. [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556). In ICLR, 2015.


